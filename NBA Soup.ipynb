{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "# Two new \n",
    "import requests \n",
    "requests.packages.urllib3.disable_warnings()\n",
    "#Requests enables us to download raw html as text\n",
    "from bs4 import BeautifulSoup \n",
    "# BeautifulSoup enables us to navigate html in python with dom-like tree structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://www.reddit.com/r/nba/\"\n",
    "r = requests.get(url, timeout=20,verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\n<!doctype html>\\n<html>\\n  <head>\\n    <title>Too Many Requests</title>\\n    <style>\\n      body {\\n          font: small verdana, arial, helvetica, sans-serif;\\n          width: 600px;\\n          margin: 0 auto;\\n      }\\n\\n      h1 {\\n          height: 40px;\\n          background: transparent url(//www.redditstatic.com/reddit.com.header.png) no-repeat scroll top right;\\n      }\\n    </style>\\n  </head>\\n  <body>\\n    <h1>whoa there, pardner!</h1>\\n    \\n\\n\\n<p>we\\'re sorry, but you appear to be a bot and we\\'ve seen too many requests\\nfrom you lately. we enforce a hard speed limit on requests that appear to come\\nfrom bots to prevent abuse.</p>\\n\\n<p>if you are not a bot but are spoofing one via your browser\\'s user agent\\nstring: please change your user agent string to avoid seeing this message\\nagain.</p>\\n\\n<p>please wait 4 second(s) and try again.</p>\\n\\n    <p>as a reminder to developers, we recommend that clients make no\\n    more than <a href=\"http://github.com/reddit/reddit/wiki/API\">one\\n    request every two seconds</a> to avoid seeing this message.</p>\\n  </body>\\n</html>\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_html = r.text\n",
    "time.sleep(1)\n",
    "raw_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print len(raw_html.split('thing id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhtn6br  spilcm Looks supercool! \n",
      "\n",
      "dcibwjg  spilcm good idea. thanks. :)\n",
      "\n",
      "dcibval  spilcm changed the text to \"Find Concerts, Tour dates, &amp; Tickets\" to make it more clear. \n",
      "\n",
      "\n",
      "\n",
      "dcibq1l  spilcm Interesting idea to use the  'I'm Feeling Lucky' concept.  I'm not sure though how to implement it...\n",
      "\n",
      "dcibl9f  spilcm Thanks for the great suggestions. I'll definitely use some of them. \n",
      "\n",
      "\n",
      "dcfk3ug  spilcm @RookiesCha0, thanks for the feedback. \n",
      "I just spent some time on the website to improve things. First off, and perhaps the most important thing was indeed to make the coverart 'clickable'. That is now working. \n",
      "The shows (and coverart) that appears on the website is dynamically taken from the TMDB API. The TV Popular , Top Rated TV shows etc are based on ratings (not picked by me). \n",
      "\n",
      "I have concatenated pages (each page is up to 20 entries) as a workaround for pagination. \n",
      "\n",
      "\n",
      "\n",
      "dccage0  spilcm Yeah I wanted to do that as well, but couldn't find it in the API.\n",
      "\n",
      "cxz0xn4  spilcm This great for a novice like me :)\n",
      "\n",
      "cxz0us6  spilcm Updated! \n",
      "\n",
      "cxmssj6  spilcm Looks good! Do you use any API to scrape the information?\n",
      "\n",
      "cxlm9mt  spilcm Sorry for that. \n",
      "\n",
      "cxku2k2  spilcm was just starting to pick up Django again, looks like a good timing. :)\n",
      "\n",
      "cxhwj6q  spilcm http://www.whyineedajob.com/ - for finding cool gadgets\n",
      "http://searchconcert.com/ - for finding available concert tickets\n",
      "http://tvlistr.com/  - for TV shows thats airing today\n",
      "\n",
      "\n",
      "cxhqtfp  spilcm Thanks. I'm using the API from TMDB.\n",
      "\n",
      "cxcj4df  spilcm Pretty neat!\n",
      "\n",
      "cu1ct2j  spilcm Thanks jwjody, I have updated the posts to use the Requests built-in decoder instead of the JSON module. \n",
      "\n",
      "cu0q6sh  spilcm Thanks for posting this. Today I added a new post on how to setup a VPS with nginx on it. (We need nginx later on to serve the Flask application.)\n",
      "\n",
      "cu0q0g0  spilcm The Flask portion of the tutorial is on its way :)\n",
      "\n",
      "cu0cl6s  spilcm You could try to create a sanitize function. Something like this should do it:\n",
      "\n",
      "def sanitize(str):\n",
      "    return str.encode('ascii','ignore')\n",
      "\n",
      "\n",
      "cty7s4j  spilcm I'm a huge fan of Django, but for this small project, I went with Flask. \n",
      "\n",
      "ctaqh66  spilcm Thanks for all the work! Is there a way to enable the function to apply patches from the UI?\n",
      "\n",
      "\n",
      "\n",
      "csigm2y  spilcm Thanks for the feedback. I will definitely do that. \n",
      "\n",
      "cshd5xp  spilcm You are right. I am actually writing one, but it takes some time considering all 40+ services AWS is offering ;)\n",
      "\n",
      "\n",
      "cshapwz  spilcm Aws provide excellent documentation and guides, but it can also be a bit overwhelming for beginners. I'll try to make it a bit clearer.\n",
      "\n",
      "ckg9lk4  spilcm I may have a bit of a bias of python, so any suggestion of Ruby (or anything else) are \n",
      "very welcome. :)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(r'http://www.reddit.com/user/spilcm/comments/.json')\n",
    "r.text\n",
    "\n",
    "data = r.json()\n",
    "\n",
    "for child in data['data']['children']:\n",
    "    print child['data']['id'], \"\", child['data']['author'],child['data']['body']\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-23 12:08:43\n",
      "2017-09-23 12:27:30\n",
      "2017-09-23 13:05:51\n",
      "2017-09-23 11:18:19\n",
      "2017-09-23 11:39:33\n",
      "2017-09-23 08:47:19\n",
      "2017-09-23 12:13:37\n",
      "2017-09-23 12:10:51\n",
      "2017-09-23 13:47:36\n",
      "2017-09-23 13:53:48\n",
      "2017-09-23 11:14:48\n",
      "2017-09-23 15:20:57\n",
      "2017-09-23 10:36:24\n",
      "2017-09-23 13:12:39\n",
      "2017-09-23 15:21:45\n",
      "2017-09-23 13:10:09\n",
      "2017-09-23 13:37:00\n",
      "2017-09-23 14:02:52\n",
      "2017-09-23 13:25:34\n",
      "2017-09-23 13:00:40\n",
      "2017-09-23 11:13:45\n",
      "2017-09-23 13:22:44\n",
      "2017-09-23 13:10:47\n",
      "2017-09-23 13:40:38\n",
      "2017-09-23 13:17:08\n",
      "2017-09-23 16:46:37\n",
      "2017-09-23 13:25:39\n",
      "2017-09-23 10:59:30\n",
      "2017-09-23 13:31:23\n",
      "2017-09-23 14:14:18\n"
     ]
    }
   ],
   "source": [
    "import praw \n",
    "import datetime\n",
    "\n",
    "reddit = praw.Reddit(client_id = 'dzjIVH_UixaDfw',\n",
    "                     client_secret = 'Bw6C3Bg0veilJSFso4vkY7LtuRc',\n",
    "                     redirecturl='http://pythonprogramming.net',\n",
    "                     user_agent = 'nbahack')\n",
    "\n",
    "subreddit = reddit.subreddit('nba')\n",
    "\n",
    "def get_date(submission):\n",
    "    time = submission.created_utc\n",
    "    return datetime.datetime.fromtimestamp(time)\n",
    "\n",
    "submissions = subreddit.hot(limit=30)\n",
    "\n",
    "for submission in submissions:\n",
    "    print (get_date(submission))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information that we know about the future games are mostly based on the court stuff that has happened to date\n",
    "\n",
    "We have historical traffic data, on-to-court info\n",
    "\n",
    "We could use All-Stars as a metric\n",
    "\n",
    "Infer future value based on future matchups\n",
    "\n",
    "\n",
    "Look at post ASG performance of All-Stars and use that to determine model\n",
    "\n",
    "How much slippage is there from ASG to end of szn? \n",
    "\n",
    "Jersey sales for leading scorers\n",
    "\n",
    "Value of the players on the court on the future games\n",
    "\n",
    "Increases in viewership, etc. in last half of year post-ASG\n",
    "\n",
    "Pretend you're presenting to marketing person who's responsible \n",
    "for some budget\n",
    "\n",
    "We could look at lead-changes, winning percentage of teams, we could use score at certain types of game\n",
    "\n",
    "Fan engagement\n",
    "\n",
    "Entertainment value:\n",
    "\n",
    "Develop composite score\n",
    "\n",
    "Some of that stuff is outlier performance\n",
    "\n",
    "We have enough data, so it'd be interesting to look at that (e.g., Westbrook)\n",
    "\n",
    "Only use variables we can compute for future games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
